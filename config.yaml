seed: 420
unet_feature_dim: 64 # ignored if render is false
dim: 128
image_size: 128
device: cpu # Use cpu, cuda or mps
randomFLip: False
training:
  learning_rate: 5e-5
  batch_size: 1
  dataset: Imagenet # Custom or Imagenet
  train_num_steps: 5
  dataset_folder: !ENV ${DATASET_PATH}
  save_intermediate_images_step: 50
  loss_type: l1 # l1 or l2 or cos
  evaluate_folder: eval

rendering:
  render: True
  extended_renderer: True
  estimate_camera: False
  view_transform: True
  camera_config:
    fov: 18
    radius: 5
  triplane_renderer_config:
    rendering_kwargs:
      ray_start: auto
      ray_end: auto
      box_warp: 2
      density_noise: 0
      depth_resolution: 32   # use 64 for visualizing (less flickering)
      depth_resolution_importance: 32  # use 64 for visualizing (less flickering)
      disparity_space_sampling: False
      clamp_mode: softplus
      white_back: False
    mlp_decoder_config:
      num_of_layers: 2
      add_global_position_as_feature: 1
      fourier_n: 4
      decoder_lr_mul: 1
      decoder_output_dim: 3
      zero_outside_triplanes: True
      decoder_time_feature: False
      lod: True

logging:
  save_dir: results/
  intermediate_outputs: results/intermediate/
  load_model: True
  model_path: model/checkpoint_generic.pt # or model/checkpoint_lightning.pt

dataset_params:
  all_classes: True

visualization:
  image_path: images/
